{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capture device is open: True\n",
      "坐标: 144_146_504_424\n",
      "测量高度146.73cm\n",
      "测量距离537.98cm\n",
      "\n",
      "\n",
      "坐标: 1_201_72_255\n",
      "无法测量\n",
      "坐标: 511_168_631_224\n",
      "测量高度79.45cm\n",
      "测量距离870.32cm\n",
      "\n",
      "\n",
      "坐标: 598_198_637_234\n",
      "测量高度31.82cm\n",
      "测量距离626.89cm\n",
      "\n",
      "\n",
      "坐标: 178_80_473_353\n",
      "测量高度187.68cm\n",
      "测量距离471.86cm\n",
      "\n",
      "\n",
      "坐标: -5_111_176_353\n",
      "测量高度188.39cm\n",
      "测量距离581.81cm\n",
      "\n",
      "\n",
      "坐标: 498_126_638_336\n",
      "测量高度114.79cm\n",
      "测量距离394.18cm\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pynq.overlays.base import BaseOverlay\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pynq.lib.video import *\n",
    "from time import sleep\n",
    "import os\n",
    "import argparse\n",
    "import camera_configs  # 摄像头的标定数据\n",
    "from my_hyperlpr import *\n",
    "from PIL import Image,ImageDraw,ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "base = BaseOverlay(\"base.bit\")\n",
    "\n",
    "weightsPath=\"/home/xilinx/jupyter_notebooks/base/video/data/yolov3.weights\"\n",
    "configPath=\"/home/xilinx/jupyter_notebooks/base/video/data/yolov3.cfg\"\n",
    "labelsPath=\"/home/xilinx/jupyter_notebooks/base/video/data/coco.names\"\n",
    "rootdir = \"/home/xilinx/jupyter_notebooks/base/video/data/photo_save/\"   #图像读取地址\n",
    "savepath = \"/home/xilinx/jupyter_notebooks/base/video/data/images_save/\"  # 图像保存地址\n",
    "\n",
    "Mode = VideoMode(640,480,24)\n",
    "hdmi_out = base.video.hdmi_out\n",
    "hdmi_out.configure(Mode,PIXEL_RGB)\n",
    "hdmi_out.start()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# 设置摄像头分辨率 宽为1280，高为480\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "print(\"Capture device is open: \" + str(cap.isOpened()))\n",
    "\n",
    "def show_chinese(imag,str,position,size,color):\n",
    "    pil_img = cv2.cvtColor(imag,cv2.COLOR_BGR2RGB)#cv2和PIL中颜色的hex码的储存顺序不同，需转RGB模式\n",
    "    pilimg = Image.fromarray(pil_img)#Image.fromarray()将数组类型转成图片格式，与np.array()相反\n",
    "    draw = ImageDraw.Draw(pilimg)#PIL图片上打印汉字\n",
    "    font = ImageFont.truetype(\"simhei.ttf\",size,encoding=\"utf-8\")\n",
    "    #参数1：字体文件路径，参数2：字体大小；Windows系统“simhei.ttf”默认存储在路径：C:\\Windows\\Fonts中\n",
    "    draw.text(position,str,color,font=font)\n",
    "    cv2img = cv2.cvtColor(np.array(pilimg),cv2.COLOR_RGB2BGR)#将图片转成cv2.imshow()可以显示的数组格式\n",
    "    return cv2img\n",
    "\n",
    "def shot(pos, frame):\n",
    "    #global i\n",
    "    path = rootdir + pos + \".jpg\"\n",
    "    cv2.imwrite(path, frame[:,:,[2,1,0]])\n",
    "    print(\"snapshot saved into: \" + path)\n",
    "\n",
    "def high_mea(x,y,threeD):\n",
    "        if (x>639)or(y>480):\n",
    "            return 0,0,0\n",
    "        else:\n",
    "            x1=(threeD[y][x][0])/200\n",
    "            y1=(threeD[y][x][1])/200\n",
    "\n",
    "        if abs(threeD[y][x][2]) < 1200000:\n",
    "            dis=round((abs(threeD[y][x][2])/200),2)\n",
    "            return x1,y1,1,dis\n",
    "        else:\n",
    "            return 0,0,0,0\n",
    "\n",
    "freq = cv2.getTickFrequency()\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "imageCount = 1    \n",
    "\n",
    "LABELS = open(labelsPath).read().strip().split(\"\\n\")  #物体类别\n",
    "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3),dtype=\"uint8\")#颜色\n",
    "\n",
    "def aaa(frame1,frame2,limit):\n",
    "    img1_rectified = cv2.remap(frame1, camera_configs.left_map1, camera_configs.left_map2, cv2.INTER_LINEAR,\n",
    "                                   cv2.BORDER_CONSTANT)\n",
    "    img2_rectified = cv2.remap(frame2, camera_configs.right_map1, camera_configs.right_map2, cv2.INTER_LINEAR,\n",
    "                                   cv2.BORDER_CONSTANT)\n",
    "\n",
    "    imgL = cv2.cvtColor(img1_rectified, cv2.COLOR_BGR2GRAY)\n",
    "    imgR = cv2.cvtColor(img2_rectified, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    out = np.hstack((img1_rectified, img2_rectified))\n",
    "    for i in range(0, out.shape[0], 30):\n",
    "        cv2.line(out, (0, i), (out.shape[1], i), (0, 255, 0), 1)\n",
    "\n",
    "    window_size = 3\n",
    "    if imgL.ndim == 2:\n",
    "        img_channels = 1\n",
    "    else:\n",
    "        img_channels = 3\n",
    "\n",
    "    stereo = cv2.StereoSGBM_create(\n",
    "            minDisparity=0,\n",
    "            numDisparities=128,  # max_disp has to be dividable by 16 f. E. HH 192, 256\n",
    "            blockSize=3,\n",
    "            P1=8 * img_channels * window_size ** 2,\n",
    "            # wsize default 3; 5; 7 for SGBM reduced size image; 15 for SGBM full size image (1300px and above); 5 Works nicely\n",
    "            P2=32 * img_channels * window_size ** 2,\n",
    "            disp12MaxDiff=1,\n",
    "            uniquenessRatio=15,\n",
    "            speckleWindowSize=200,\n",
    "            speckleRange=1,\n",
    "            preFilterCap=63,\n",
    "            mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY\n",
    "        )\n",
    "        # 对深度进行计算，获取深度矩阵\n",
    "    disparity = stereo.compute(imgL, imgR).astype(np.float32) / 16.0\n",
    "\n",
    "        # 按照深度矩阵生产深度图\n",
    "    disp = cv2.normalize(disparity, disparity, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "        # 将深度图扩展至三维空间中，其z方向的值则为当前的距离\n",
    "    threeD = cv2.reprojectImageTo3D(disparity.astype(np.float32) / 16., camera_configs.Q)\n",
    "            \n",
    "    # 必须将boxes在遍历新的图片后初始化\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "    net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
    "            #path = os.path.join(dirpath,filename)\n",
    "    image = cv2.imread(\"./data/photo_save/left.jpg\")\n",
    "    (H, W) = image.shape[:2]\n",
    "        # 得到 YOLO需要的输出层\n",
    "    ln = net.getLayerNames()\n",
    "    ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "            #从输入图像构造一个blob，然后通过加载的模型，给我们提供边界框和相关概率\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416),swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layerOutputs = net.forward(ln)\n",
    "            #在每层输出上循环\n",
    "    for output in layerOutputs:\n",
    "         #对每个检测进行循环\n",
    "         for detection in output:\n",
    "             scores = detection[5:]\n",
    "             classID = np.argmax(scores)\n",
    "             confidence = scores[classID]\n",
    "                #过滤掉那些置信度较小的检测结果\n",
    "             if confidence > 0.5:\n",
    "                #框后接框的宽度和高度\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                #边框的左上角\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "                # 更新检测出来的框\n",
    "                # 批量检测图片注意此处的boxes在每一次遍历的时候要初始化，否则检测出来的图像框会叠加\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "            # 极大值抑制\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.2,0.3)\n",
    "    Y_high1=0\n",
    "    Y_high2=0\n",
    "    high=0\n",
    "    ret_num1=0\n",
    "    flag=0\n",
    "    k=-1\n",
    "\n",
    "    if len(idxs) > 0:\n",
    "        for i in idxs.flatten() :\n",
    "             (x, y) = (boxes[i][0], boxes[i][1])\n",
    "             (w, h) = (boxes[i][2], boxes[i][3])\n",
    "             print(\"坐标: \"+str(x)+\"_\"+str(y)+\"_\"+str(x+w)+\"_\"+str(y+h))\n",
    "             dis=0\n",
    "             ret_num1=0\n",
    "             Y_high1=0\n",
    "             for num in range(1,100):\n",
    "                 x_r=int(x+num*w/100)\n",
    "                 y_r=y\n",
    "                 X_r1,Y_r1,ret1,dis1=high_mea(x_r,y_r,threeD)\n",
    "                 y_r=y+h\n",
    "                 X_r2,Y_r2,ret2,dis2=high_mea(x_r,y_r,threeD)\n",
    "                 if (ret1==1)and(ret2==1):\n",
    "                     Y_high1=Y_high1+abs(Y_r1-Y_r2)\n",
    "                     ret_num1=ret_num1+1\n",
    "                     dis=dis+dis1+dis2\n",
    "             if ret_num1==0 :\n",
    "                print(\"无法测量\")\n",
    "             else :\n",
    "                 high=Y_high1/ret_num1 \n",
    "                 dis_f=dis/(2*ret_num1)\n",
    "                 print(\"测量高度\" +str(round(high,2))+\"cm\")\n",
    "                 print(\"测量距离\" +str(round(dis_f,2))+\"cm\")\n",
    "                 print('\\n')\n",
    "                 if high>limit:\n",
    "                     pr = LPR(\"models\")            \n",
    "                     res,left,top,right,bottom=pr.plate_recognition(frame1)\n",
    "                     #print(left,top,right,bottom)\n",
    "                     if right>=x & left<=x+w & top>=y & bottom<=y+h: \n",
    "                         cv2.rectangle(image, (x, y), (x + w, y + h), (0,0,255), 2)\n",
    "                         image=show_chinese(image, \"高度:\"+str(round(high,2))+\"cm\", (x , y ),20,(0,0,255))\n",
    "                         image=show_chinese(image, \"距离:\"+str(round(dis_f,2))+\"cm\", (x , y+20 ),20,(0,0,255))\n",
    "                         image=show_chinese(image,\"车牌:\"+res,(x , y+40 ),20,(0,0,255))\n",
    "                         flag=1\n",
    "        if flag==0:\n",
    "            image=show_chinese(image, \"未检测到超高车辆\", (0, 0),30,(0,0,255))\n",
    "        else:\n",
    "            image=show_chinese(image,\"检测到超高车辆\",(0 , 0 ),30,(0,0,255))\n",
    "                \n",
    "    cv2.imwrite(savepath+\"total\"+\".jpg\",image)\n",
    "    return image\n",
    "\n",
    "outframe = hdmi_out.newframe()\n",
    "stage = 2\n",
    "limit=190\n",
    "while cap.isOpened():    \n",
    "    if base.buttons[0].read()==1:\n",
    "        stage=0\n",
    "        sleep(0.1)\n",
    "    if base.buttons[1].read()==1:\n",
    "        stage=1\n",
    "        sleep(0.1)\n",
    "    if base.buttons[2].read()==1:\n",
    "        limit=limit+5\n",
    "        sleep(0.1)\n",
    "    if base.buttons[3].read()==1:\n",
    "        limit=limit-5\n",
    "        sleep(0.1)\n",
    "        \n",
    "    if stage == 0:\n",
    "        ret, frame = cap.read()\n",
    "        outframe[:,:,:] = frame[:,0:640,:]\n",
    "        hdmi_out.writeframe(outframe)\n",
    "    if stage == 1:\n",
    "        ret, frame = cap.read()\n",
    "        left_img = frame[:, 0:640, :]\n",
    "        right_img = frame[:, 640:1280, :]\n",
    "        shot(\"left\", left_img)\n",
    "        shot(\"right\", right_img)\n",
    "        frame1 = cv2.imread(\"./data/photo_save/left.jpg\")   \n",
    "        frame2 = cv2.imread(\"./data/photo_save/right.jpg\")  \n",
    "        image=aaa(frame1,frame2,limit)\n",
    "        outframe[:,:,:] = image[0:480,0:640,:]\n",
    "        hdmi_out.writeframe(outframe)\n",
    "        stage=4\n",
    "    if stage == 2:\n",
    "        img = cv2.imread(\"./data/main.jpg\")\n",
    "        cv2.putText(img, str(limit), (360, 420), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 0), 2)\n",
    "        outframe[:,:,:] = img[:,:,:]\n",
    "        hdmi_out.writeframe(outframe)\n",
    "    if stage == 3:\n",
    "        break\n",
    "print(\"End\" )\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
